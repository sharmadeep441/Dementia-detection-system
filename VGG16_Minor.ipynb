{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VGG16_Minor.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sharmadeep441/Dementia-detection-system/blob/main/VGG16_Minor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pwYg6RJRfMBk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import skimage.io\n",
        "import os \n",
        "import tqdm\n",
        "import glob\n",
        "import tensorflow \n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from skimage.io import imread, imshow\n",
        "from skimage.transform import resize\n",
        "from skimage.color import grey2rgb\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import InputLayer, BatchNormalization, Dropout, Flatten, Dense, Activation, MaxPool2D, Conv2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8TtDVTBfOpP",
        "outputId": "85d0069c-4cb0-4e35-bcea-ccfb7707e826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd ~/dataaa\n",
        "\n",
        "\n",
        "fileId = '1k9objkB5kqv30TgS1HHYybHmA2rPm_M0'\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import copy\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "os.makedirs('datasets')\n",
        "os.chdir('datasets')\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileName = fileId + '.zip'\n",
        "downloaded = drive.CreateFile({'id': fileId})\n",
        "downloaded.GetContentFile(fileName)\n",
        "ds = ZipFile(fileName)\n",
        "ds.extractall()\n",
        "os.remove(fileName)\n",
        "print('Extracted zip file ' + fileName)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NDw899OfRFQ",
        "outputId": "d113f305-8be8-49f9-9c71-16057389a64a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/root/dataaa'\n",
            "/content\n",
            "Extracted zip file 1k9objkB5kqv30TgS1HHYybHmA2rPm_M0.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   rotation_range=30,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True,\n",
        "                                   vertical_flip=True,\n",
        "                                   validation_split = 0.2)\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   validation_split = 0.2)\n",
        "\n",
        "test_datagen  = ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "8oGdh3hffsfc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset  = train_datagen.flow_from_directory(directory = '/content/datasets/Alzheimer_s Dataset/train',\n",
        "                                                   target_size = (224,224),\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   subset = 'training',\n",
        "                                                   batch_size = 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YeUJzdnnfwB6",
        "outputId": "8a403941-710e-4868-e2e7-7a9fc6eef646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4098 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_dataset = valid_datagen.flow_from_directory(directory = '/content/datasets/Alzheimer_s Dataset/train',\n",
        "                                                  target_size = (224,224),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  subset = 'validation',\n",
        "                                                  batch_size = 128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AUvSmRAofyW7",
        "outputId": "fe888e16-e56e-44de-fa5b-dec490585ccd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1023 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = VGG16(input_shape=(224,224,3), \n",
        "                   include_top=False,\n",
        "                   weights=\"imagenet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "067dyYUpf1nm",
        "outputId": "c945f1c1-811f-4d38-a2d8-cf76cb34ddd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Freezing Layers\n",
        "#no need to train weights\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable=False"
      ],
      "metadata": {
        "id": "jlfAjnEaf3nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Building Model\n",
        "\n",
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Flatten())\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(2048,kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1024,kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(4,activation='softmax'))"
      ],
      "metadata": {
        "id": "MKOb-I8Gf5oK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Summary\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys5ySTref8P5",
        "outputId": "ea6abad8-7840-4d5c-a964-a71eb6cd4366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " vgg16 (Functional)          (None, 7, 7, 512)         14714688  \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 25088)            100352    \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2048)              51382272  \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 2048)             8192      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation (Activation)     (None, 2048)              0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              2098176   \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 1024)              0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 4)                 4100      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 68,311,876\n",
            "Trainable params: 53,540,868\n",
            "Non-trainable params: 14,771,008\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Compile \n",
        "\n",
        "OPT    = tensorflow.keras.optimizers.Adam(lr=0.001)\n",
        "METRIC = tensorflow.keras.metrics.AUC(name = 'auc')\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              metrics=METRIC,\n",
        "              optimizer=OPT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h3EIvxuCf-Pg",
        "outputId": "f1af0a23-e96b-4607-e14c-55ef359aa198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_history=model.fit(train_dataset,\n",
        "                        validation_data=valid_dataset,\n",
        "                        epochs = 10,\n",
        "                        verbose = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unhlj1higAOh",
        "outputId": "09a70909-7694-451e-a1b3-e3e1c8c06caa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the model to disk\n",
        "import pickle\n",
        "pickle.dump(model, open('vgg_model.p', 'wb'))"
      ],
      "metadata": {
        "id": "LXCfup8-ldwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = pickle.load(open('vgg_model.p','rb'))"
      ],
      "metadata": {
        "id": "m6xld5CgmC85"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}